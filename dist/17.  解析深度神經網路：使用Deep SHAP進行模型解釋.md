# [Day 17] è§£ææ·±åº¦ç¥ç¶“ç¶²è·¯ï¼šä½¿ç”¨Deep SHAPé€²è¡Œæ¨¡å‹è§£é‡‹
## Feature Attribution
Feature Attribution(ç‰¹å¾µæ­¸å› )æ˜¯æ©Ÿå™¨å­¸ç¿’é ˜åŸŸä¸­çš„ä¸€å€‹é‡è¦æ¦‚å¿µï¼Œå®ƒç”¨æ–¼è§£é‡‹æ¨¡å‹çš„é æ¸¬çµæœã€‚ç•¶æˆ‘å€‘è¨“ç·´æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ï¼Œç‰¹åˆ¥æ˜¯æ·±åº¦å­¸ç¿’æ¨¡å‹ï¼Œé€™äº›æ¨¡å‹é€šå¸¸æ˜¯é»‘ç›’å­ï¼Œé›£ä»¥ç†è§£ç‚ºä»€éº¼æ¨¡å‹æœƒåšå‡ºç‰¹å®šçš„é æ¸¬ã€‚å› æ­¤`ç‰¹å¾µæ­¸å› `çš„ç›®æ¨™æ˜¯æ‰¾å‡ºæ¨¡å‹ä¸­æ¯å€‹è¼¸å…¥ç‰¹å¾µå°æ–¼æœ€çµ‚é æ¸¬çš„è²¢ç»æˆ–å½±éŸ¿ç¨‹åº¦ï¼Œé€™æœ‰åŠ©æ–¼æˆ‘å€‘ç†è§£æ¨¡å‹çš„é‹ä½œåŸç†ï¼Œä¸¦æª¢æŸ¥æ¨¡å‹æ˜¯å¦ä¾æ“šæˆ‘å€‘çš„æœŸæœ›é‹ä½œï¼Œä»¥åŠç™¼ç¾å¯èƒ½çš„åå·®æˆ–ä¸å…¬å¹³æ€§ã€‚åœ¨æ©Ÿå™¨å­¸ç¿’ä¸­ï¼Œç‰¹å¾µæ­¸å› é€šå¸¸æœ‰ä»¥ä¸‹å¹¾ç¨®å¸¸è¦‹çš„æ–¹æ³•ï¼š

- ç‰¹å¾µé‡è¦æ€§ï¼ˆFeature Importanceï¼‰ï¼šé€™ç¨®æ–¹æ³•è¡¡é‡äº†æ¯å€‹ç‰¹å¾µå°æ–¼æ¨¡å‹é æ¸¬çš„å½±éŸ¿ç¨‹åº¦ï¼Œå¯ä»¥é€é LIME æˆ– SHAP ç­‰è§£é‡‹å·¥å…·é€²è¡Œç‰¹å¾µé‡è¦æ€§åˆ†æã€‚
    - SHAPï¼ˆSHapley Additive exPlanationsï¼‰ï¼šSHAP åŸºæ–¼åšå¼ˆè«–çš„æ¦‚å¿µï¼Œå®ƒè©¦åœ–å°‡æ¯å€‹ç‰¹å¾µçš„è²¢ç»åˆ†é…çµ¦æ¨¡å‹é æ¸¬çš„çµæœã€‚Shapley valuesç¶œåˆè€ƒæ…®äº†ç‰¹å¾µçš„é‡è¦æ€§ä»¥åŠç‰¹å¾µä¹‹é–“çš„äº¤äº’ä½œç”¨ï¼Œå› æ­¤åœ¨è§£é‡‹è¤‡é›œæ¨¡å‹æ™‚å¾ˆæœ‰ç”¨ã€‚
    - LIMEï¼ˆLocal Interpretable Model-agnostic Explanationsï¼‰ï¼šLIME é€šå¸¸ç”¨æ–¼è§£é‡‹æŸç­†è³‡æ–™ç‚ºä½•åšå‡ºé€™æ¨£åˆ¤æ–·ï¼Œå®ƒä¸»è¦ç”Ÿæˆä¸€å€‹ç°¡å–®å¯è§£é‡‹çš„ç·šæ€§æ¨¡å‹ï¼Œä¾†è§£é‡‹æ¨¡å‹çš„é æ¸¬ã€‚
- åŸºæ–¼æ¢¯åº¦æ–¹æ³•ï¼ˆGradient-Based Methodsï¼‰ï¼šé€™äº›æ–¹æ³•åŸºæ–¼æ¨¡å‹çš„æ¢¯åº¦è¨Šæ¯ï¼Œè©¦åœ–æ‰¾å‡ºå“ªäº›ç‰¹å¾µå°æ–¼æŸå€‹é æ¸¬çš„æ¢¯åº¦è²¢ç»æœ€å¤§ã€‚
- é®ç½©æˆ–å±è”½æ–¹æ³•ï¼ˆMasking or Perturbation Methodsï¼‰ï¼šé€™äº›æ–¹æ³•é€šéå°è¼¸å…¥ç‰¹å¾µé€²è¡Œä¿®æ”¹ï¼Œè§€å¯Ÿæ¨¡å‹é æ¸¬çš„è®ŠåŒ–ï¼Œä¾†è©•ä¼°æ¯å€‹ç‰¹å¾µçš„é‡è¦æ€§ã€‚ä¾‹å¦‚å¯ä»¥å°‡æŸå€‹ç‰¹å¾µçš„å€¼è¨­ç½®ç‚ºé›¶ï¼Œç„¶å¾Œè§€å¯Ÿé æ¸¬çš„è®ŠåŒ–ã€‚

## Additive Feature Attribution Methods
Additive Feature Attribution(AFA) æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°‡ä¸€å€‹æ¨¡å‹çš„é æ¸¬åˆ†è§£æˆæ¯å€‹ç‰¹å¾µçš„è²¢ç»éƒ¨åˆ†ï¼Œé€™æ¨£å¯ä»¥æ›´å®¹æ˜“ç†è§£æ¨¡å‹çš„æ±ºç­–éç¨‹ã€‚è©²æ–¹æ³•æ—¨åœ¨ç†è§£æ¯å€‹ç‰¹å¾µå°æ¨¡å‹é æ¸¬çš„è²¢ç»ï¼Œå®ƒå€‘å‡è¨­æ¨¡å‹å°æ–¼è¼¸å…¥ç‰¹å¾µçš„é æ¸¬æ˜¯å¯åˆ†è§£çš„ï¼Œå› æ­¤æ¨¡å‹çš„é æ¸¬å¯ä»¥è¢«åˆ†è§£æˆæ¯å€‹ç‰¹å¾µçš„å½±éŸ¿ï¼Œä¸¦ä¸”é€™äº›å½±éŸ¿æ˜¯å¯ä»¥ç›¸åŠ çš„ã€‚ä¸€äº›è§£é‡‹æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é æ¸¬çš„æ–¹æ³•ï¼Œä¾‹å¦‚ LIMEã€SHAPã€DeepLIFT å’Œ Layer-Wise Relevance Propagationï¼Œé€™äº›æ–¹æ³•éƒ½å±¬æ–¼ AFA çš„å®¶æ—å…¶ä¸­ä¸€å“¡ã€‚AFA æ–¹æ³•çš„åŸºæœ¬å®šç¾©å¦‚ä¸‹ï¼š

![](./image/img17-1.png)

- gæ˜¯ä¸€å€‹ç°¡å–®çš„å¯è§£é‡‹æ¨¡å‹ï¼Œå®ƒå¯èƒ½æ˜¯ä¸€å€‹ç”¨æ–¼è§£é‡‹è¤‡é›œæ¨¡å‹çš„æ¨¡å‹ï¼Œé€šå¸¸æ˜¯ä¸€å€‹ç·šæ€§æ¨¡å‹æˆ–é¡ä¼¼çš„ç°¡å–®æ¨¡å‹ã€‚
- å¼å­ä¸­çš„æ¯å€‹ğœ™iä»£è¡¨ç¬¬iå€‹ç‰¹å¾µçš„å½±éŸ¿ç¨‹åº¦æˆ–é‡è¦æ€§ã€‚ç•¶ä¸€å€‹ç‰¹å¾µçš„ğœ™iå€¼è¼ƒå¤§æ™‚ï¼Œæ„å‘³è‘—é€™å€‹ç‰¹å¾µå°æ¨¡å‹çš„é æ¸¬æœ‰è¼ƒå¤§çš„å½±éŸ¿ã€‚
- ğ‘§â€²æ˜¯ä¸€å€‹ç”±0å’Œ1çµ„æˆçš„äºŒå…ƒå‘é‡ï¼Œå…¶ä¸­Mä»£è¡¨ç°¡åŒ–ç‰¹å¾µçš„æ•¸é‡ã€‚é€™å€‹å‘é‡è¡¨ç¤ºäº†åœ¨æ¨¡å‹ä¸­å“ªäº›ç‰¹å¾µè¢«è€ƒæ…®åˆ°ï¼Œå“ªäº›æ²’æœ‰è¢«è€ƒæ…®åˆ°ã€‚ç•¶ç‰¹å¾µåœ¨å‘é‡ä¸­å°æ‡‰çš„ä½ç½®æ˜¯1æ™‚ï¼Œè¡¨ç¤ºé€™å€‹ç‰¹å¾µåœ¨æ¨¡å‹ä¸­è¢«è€ƒæ…®åˆ°äº†ï¼›ç•¶å°æ‡‰ä½ç½®æ˜¯0æ™‚ï¼Œè¡¨ç¤ºè©²ç‰¹å¾µæœªè¢«è€ƒæ…®ã€‚

ç°¡å–®ä¾†èªªï¼ŒAFA æ–¹æ³•çš„ç›®æ¨™æ˜¯é€šéä¸€å€‹ç°¡å–®çš„å¯è§£é‡‹æ¨¡å‹ g ä¾†è§£é‡‹è¤‡é›œæ¨¡å‹çš„é æ¸¬ã€‚å®ƒä½¿ç”¨äºŒå…ƒå‘é‡ ğ‘§â€² ä¾†è¡¨ç¤ºå“ªäº›ç‰¹å¾µåœ¨è§£é‡‹ä¸­è¢«è€ƒæ…®ï¼Œä¸¦ä½¿ç”¨ ğœ™i ä½œç‚ºæ¬Šé‡ä¾†é‡åŒ–æ¯å€‹ç‰¹å¾µå°é æ¸¬çš„å½±éŸ¿ç¨‹åº¦ã€‚é€™æ¨£çš„æ–¹æ³•æœ‰åŠ©æ–¼ç†è§£æ¨¡å‹æ˜¯å¦‚ä½•æ ¹æ“šä¸åŒçš„ç‰¹å¾µä¾†åšå‡ºé æ¸¬çš„ï¼Œæé«˜äº†æ¨¡å‹çš„å¯è§£é‡‹æ€§ã€‚ä¸åŒçš„ AFA æ–¹æ³•å¯èƒ½ä½¿ç”¨ä¸åŒçš„æŠ€è¡“ä¾†è¨ˆç®— ğœ™i å€¼ï¼Œä½†å®ƒå€‘éƒ½éµå¾ªé€™å€‹åŸºæœ¬æ¡†æ¶é€²è¡Œæ¨¡å‹è§£é‡‹ã€‚

## Deep SHAP (DeepLIFT + Shapley Values)
ä»Šå¤©è¦ä»‹ç´¹åœ¨ SHAP å¥—ä»¶ä¸­çš„ Deep SHAP æ–¹æ³•ï¼Œå®ƒçµåˆäº† DeepLIFT å’Œ Shapley values çš„æ¦‚å¿µï¼Œä»¥è¨ˆç®—æ¯å€‹ç‰¹å¾µå°æ–¼æ¨¡å‹é æ¸¬çš„è²¢ç»ï¼Œä½¿æ›´å¥½åœ°è§£é‡‹ç¥ç¶“ç¶²è·¯æ¨¡å‹çš„é æ¸¬ã€‚

![](./image/img17-2.png)

- [DeepLIFT](https://arxiv.org/abs/1704.02685) (Deep Learning Important FeaTures)ï¼šæ˜¯åŸºæ–¼åå‘å‚³æ’­çš„è§£é‡‹æ–¹æ³•ï¼Œé€éæ¯”è¼ƒæ¨¡å‹çš„é æ¸¬è¼¸å‡ºèˆ‡åƒè€ƒè¼¸å‡ºä¹‹é–“çš„å·®ç•°ä¾†è¨ˆç®—æ¯å€‹è¼¸å…¥ç‰¹å¾µå°é æ¸¬çš„è²¢ç»ã€‚ä½¿å¾—æˆ‘å€‘å¯ä»¥äº†è§£æ¯å€‹ç‰¹å¾µå°æ¨¡å‹é æ¸¬çš„ç›¸å°å½±éŸ¿ã€‚

- Shapley Valuesï¼šç”¨æ–¼è©•ä¼°æ¯å€‹ç‰¹å¾µå°æ¨¡å‹é æ¸¬çš„å½±éŸ¿ã€‚å®ƒè€ƒæ…®äº†æ¯å€‹ç‰¹å¾µçš„ä¸åŒæ’åˆ—çµ„åˆï¼Œä»¥ç¢ºå®šæ¯å€‹ç‰¹å¾µçš„è²¢ç»åº¦ã€‚ä½¿å¾—æˆ‘å€‘å¯ä»¥æ›´å¥½åœ°ç†è§£æ¨¡å‹é æ¸¬èƒŒå¾Œçš„ç‰¹å¾µé‡è¦æ€§ã€‚

> ä»Šå¤©çš„ç·´ç¿’å°‡ä½¿ç”¨ SHAP å¥—ä»¶ä¸­çš„ DeepExplainer(Deep SHAP) æ–¹æ³•ä½œç‚ºå±•ç¤ºã€‚

## [å¯¦ä½œ] ä½¿ç”¨ Deep SHAP è§£é‡‹ DNN æ¨¡å‹
æœ¬æ—¥ç¯„ä¾‹å°‡é€é TensorFlow å¯¦ä½œ DNN æ¨¡å‹ï¼Œä¸¦ä½¿ç”¨ sklearn çš„è³‡æ–™é›† [fetch_california_housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) ä¾†é æ¸¬åŠ å·åœ°å€çš„æˆ¿å±‹åƒ¹æ ¼ä¸­ä½æ•¸ã€‚é€™å€‹è³‡æ–™é›†åŒ…å«äº† 8 å€‹ç‰¹å¾µï¼Œåˆ†åˆ¥æ˜¯ï¼š


- MedIncï¼šè©²å€åŸŸå…§å®¶åº­æ”¶å…¥çš„ä¸­ä½æ•¸
- HouseAgeï¼šè©²å€åŸŸå…§æˆ¿å±‹çš„å¹³å‡æˆ¿é½¡
- AveRoomsï¼šè©²å€åŸŸå…§æˆ¿å±‹çš„å¹³å‡æˆ¿é–“æ•¸
- AveBedrmsï¼šè©²å€åŸŸå…§æˆ¿å±‹çš„å¹³å‡è‡¥å®¤æ•¸
- Populationï¼šè©²å€åŸŸå…§äººå£æ•¸
- AveOccupï¼šè©²å€åŸŸå…§å¹³å‡æ¯å€‹æˆ¿å±‹çš„å±…ä½äººæ•¸
- Latitudeï¼šè©²å€åŸŸå…§æˆ¿å±‹æ‰€åœ¨ç·¯åº¦
- Longitudeï¼šè©²å€åŸŸå…§æˆ¿å±‹æ‰€åœ¨ç¶“åº¦

é€™å€‹è³‡æ–™é›†åŒ…å«äº† 20640 ç­†æ¨£æœ¬ï¼Œæ¯å€‹æ¨£æœ¬éƒ½æœ‰ä¸Šè¿° 8 å€‹ç‰¹å¾µä»¥åŠæˆ¿å±‹åƒ¹æ ¼ä¸­ä½æ•¸ä½œç‚ºç›®æ¨™è®Šæ•¸ã€‚

```py
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
import numpy as np

# è¼‰å…¥åŠ å·åœ°å€æˆ¿å±‹åƒ¹æ ¼é æ¸¬è³‡æ–™é›†
data = fetch_california_housing()
x_feature_names = np.array(data.feature_names)
X, y = data.data, data.target

# åˆ‡åˆ†è³‡æ–™é›†ç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.001, random_state=42)
```

## å»ºç«‹èˆ‡è¨“ç·´ç¥ç¶“ç¶²è·¯
ä»¥ä¸‹ç¨‹å¼ç¢¼ä½¿ç”¨ Tensorflow2.0 Functional API æ­å»ºç¥ç¶“ç¶²è·¯ã€‚æ­¤æ¨¡å‹æ¥å—ä¸€å€‹è¼¸å…¥ï¼Œç„¶å¾Œé€šéä¸€ç³»åˆ—ç¥ç¶“ç¶²è·¯å±¤é€²è¡Œè™•é‹ç®—ï¼Œæœ€å¾Œè¼¸å‡ºä¸€å€‹å–®ä¸€çš„æ•¸å€¼å³ç‚ºæˆ¿å±‹åƒ¹æ ¼ä¸­ä½æ•¸ã€‚æ¨¡å‹çš„å±¤æ¬¡çµæ§‹åŒ…æ‹¬ï¼šä¸€å€‹æ­£è¦åŒ–å±¤ï¼ˆNormalizationï¼‰ç”¨æ–¼å°è¼¸å…¥é€²è¡Œæ­£è¦åŒ–ï¼Œä¸‰å€‹å…¨é€£æ¥å±¤ï¼ˆDenseï¼‰ç”¨æ–¼æå–ç‰¹å¾µå’Œå­¸ç¿’æ¨¡å‹çš„æ˜ å°„ï¼Œæœ€å¾Œä¸€å€‹å…¨é€£æ¥å±¤è¼¸å‡ºå–®ä¸€å€¼ï¼Œä¸¦ä½¿ç”¨ ReLU æ¿€ç™¼å‡½æ•¸é”åˆ°éç·šæ€§è½‰æ›ã€‚

```py
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.models import Model

def build_model():
    # è³‡æ–™æ­£è¦åŒ–
    model_input = layers.Input(shape=X.shape[-1])
    norm_layer = tf.keras.layers.Normalization(axis=1)
    norm_layer.adapt(X_train)
    x = norm_layer(model_input)
    # ç¬¬ä¸€å±¤éš±è—å±¤
    x = layers.Dense(32,activation='relu')(x)
    # ç¬¬äºŒå±¤éš±è—å±¤
    x = layers.Dense(64,activation='relu')(x)
    # è¼¸å‡ºå±¤
    model_output = layers.Dense(1,activation='relu')(x)
    return Model(model_input ,model_output)
```

æ¥ä¸‹ä¾†ï¼Œä½¿ç”¨ä¹‹å‰å®šç¾©çš„ `build_model()` å‡½æ•¸å»ºç«‹ä¸€å€‹æ–°çš„ç¥ç¶“ç¶²çµ¡æ¨¡å‹ï¼Œä¸¦å°‡é€™å€‹æ¨¡å‹å­˜å„²åœ¨ model è®Šæ•¸ä¸­ã€‚æœ€å¾Œä½¿ç”¨ `model.summary()` å°å‡ºæ¨¡å‹çš„æ‘˜è¦è¨Šæ¯ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„çµæ§‹ã€æ¯ä¸€å±¤çš„åƒæ•¸æ•¸é‡ç­‰ã€‚

```py
tf.keras.backend.clear_session()
model = build_model()
model.summary()
```

![](./image/img17-3.png)

æ¨¡å‹æº–å‚™å°±ç·’å¾Œå³å¯é–‹å§‹è¨“ç·´æ¨¡å‹ã€‚é€™è£¡ä½¿ç”¨ Adam å„ªåŒ–å™¨è¨­å®šå­¸ç¿’ç‡ç‚º 0.001ï¼Œä¸¦ä½¿ç”¨å‡æ–¹èª¤å·®ï¼ˆMSEï¼‰ä½œç‚ºæå¤±å‡½æ•¸ã€‚æ¥ä¸‹ä¾†è¨­å®šæ‰¹æ¬¡å¤§å°ç‚º 64ï¼Œè¨“ç·´è¿­ä»£æ¬¡æ•¸ç‚º 50 æ¬¡ã€‚æœ€å¾Œä½¿ç”¨è¨“ç·´æ•¸æ“š X_train å’Œ y_train ä¾†è¨“ç·´æ¨¡å‹ã€‚

```py
from tensorflow.keras.optimizers import Adam

# ç·¨è­¯æ¨¡å‹
optim = Adam(learning_rate=0.001)
model.compile(loss='mse',
              optimizer=optim)

batch_size=64
epochs = 50

# è¨“ç·´æ¨¡å‹
history = model.fit(X_train, y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    shuffle=True,
                    validation_split=0.1)
```

## Deep SHAP è§£é‡‹æ¨¡å‹
ä»¥ä¸‹å»ºç«‹ä¸€å€‹ DeepExplainer è§£é‡‹å™¨ï¼Œä¸¦æŒ‡å®šäº†è¦è§£é‡‹çš„æ¨¡å‹ï¼ˆmodelï¼‰å’Œè¨“ç·´æ•¸æ“šï¼ˆX_trainï¼‰ã€‚ç„¶å¾Œé€é Deep SHAP ä¾†ä¼°è¨ˆ Shapley valuesï¼Œä¸¦å°‡å…¶å­˜å„²åœ¨ shap_values è®Šæ•¸ä¸­ã€‚

```py
import shap
shap.initjs()

# ä½¿ç”¨ Deep SHAP è§£é‡‹æ¨¡å‹
explainer = shap.DeepExplainer(model=model, data=X_train)
# ä¼°è¨ˆ Shapley values
shap_values = explainer.shap_values(X_test)
```

### SHAP Summary Plot (å…¨å±€è§£é‡‹)
æˆ‘å€‘å¯ä»¥é€é SHAP Summary Plot é€²è¡Œæ¨¡å‹çš„å…¨å±€è§£é‡‹ï¼Œè©²åœ–è¡¨é¡¯ç¤ºæ¯å€‹ç‰¹å¾µè®Šé‡å°æ•´é«”å¹³å‡æ¨¡å‹è¼¸å‡ºçš„å¹³å‡å½±éŸ¿ã€‚åœ¨è©²åœ–è¡¨ä¸­ï¼Œæˆ‘å€‘å¯ä»¥çœ‹åˆ°æ¯å€‹ç‰¹å¾µå°æ–¼æ¨¡å‹çš„é æ¸¬è¼¸å‡ºçš„å¹³å‡è²¢ç»ç¨‹åº¦ï¼Œæœ‰åŠ©æ–¼ç†è§£å“ªäº›ç‰¹å¾µå°æ¨¡å‹çš„é æ¸¬èµ·è‘—é‡è¦ä½œç”¨ï¼Œå“ªäº›ç‰¹å¾µå½±éŸ¿è¼ƒå°ã€‚å¾åˆ†æçµæœå¯ä»¥ç™¼ç¾åœ°ç†ä½ç½®(ç¶“ç·¯åº¦)ä»¥åŠå®¶åº­æ”¶å…¥å’Œæˆå“¡æ•¸å°æ–¼é æ¸¬è©²åœ°å€æˆ¿åƒ¹æ˜¯æœ‰é¡¯è‘—çš„å½±éŸ¿æ€§ã€‚

```py
# ç²å¾—æ¯å€‹ç‰¹å¾µå°æ–¼æ•´é«”å¹³å‡è²¢ç»çš„å€¼
shap.summary_plot(shap_values[0], X_test, class_names=['median house value'], feature_names=x_feature_names)
```

![](./image/img17-4.png)

### SHAP Force plot (å–®ç­†è³‡æ–™è§£é‡‹)
ç”±æ–¼æˆ‘å€‘å¾è³‡æ–™é›†åˆ‡å‰² 21 ç­†ä½œç‚ºæ¸¬è©¦é›†ï¼Œå‰›å‰›ä¸Šé¢çš„å…¨å±€è§£é‡‹æ˜¯é‡å°é€™ 21 ç­†è³‡æ–™é€²è¡Œå¹³å‡æ•´é«”æ€§è§£é‡‹ã€‚æ¥è‘—æˆ‘å€‘ä¸€æ¨£å¯ä»¥é‡å°æ¯ä¸€ç­†æ•¸æ“šé€²è¡Œè§£é‡‹åˆ†æã€‚é¦–å…ˆç¨‹å¼ä¸­çš„ index è¢«è¨­å®šç‚º0ï¼Œè¡¨ç¤ºæˆ‘å€‘è¦è§€å¯Ÿæ¸¬è©¦é›†ä¸­çš„ç¬¬ä¸€ç­†è³‡æ–™ã€‚æ¥è‘—ä½¿ç”¨ `force_plot` å°é€™ç­†è³‡æ–™é€²è¡Œé æ¸¬ï¼Œä¸¦å°‡åˆ†æçµæœè¦–è¦ºåŒ–å‘ˆç¾ã€‚

```py
# è§€å¯Ÿæ¸¬è©¦é›†ä¸­ç¬¬ä¸€ç­†è³‡æ–™é æ¸¬é‡è¦ç¨‹åº¦
index=0
print(f'æ¸¬è©¦é›†ç¬¬ {index+1} ç­†æ¨¡å‹é æ¸¬çµæœ: {model.predict(X_test[[index], :])[0]}')
shap.force_plot(explainer.expected_value.numpy(),
                 shap_values[0][0][index],
                 X_test[index],
                 feature_names=x_feature_names)
```

> å¯ä»¥è©¦è‘—èª¿æ•´ index æ•¸å€¼(0~20)è§€å¯Ÿæ¸¬è©¦é›†ä¸­ä¸åŒè³‡æ–™é»çš„è§£é‡‹

![](./image/img17-5.png)

### SHAP waterfall plot (å–®ç­†è³‡æ–™è§£é‡‹)
ç€‘å¸ƒåœ–æ˜¯ä¸€ç¨®èƒ½å¤ ä»¥è¦–è¦ºæ–¹å¼å‘ˆç¾å–®ä¸€é æ¸¬è§£é‡‹çµæœçš„å·¥å…·ã€‚ç€‘å¸ƒåœ–çš„èµ·é»æ˜¯æ¨¡å‹è¼¸å‡ºçš„åŸºæº–å€¼ E[f(z)]ï¼Œä»£è¡¨æ¨¡å‹åœ¨ä¸çœ‹ä»»ä½•ç‰¹å¾µç‹€æ³ä¸‹é æ¸¬çš„æ•¸å€¼ï¼ˆğœ™0ï¼‰ã€‚ç„¶å¾Œæ¯ä¸€å€‹æ¢éƒ½è¨˜éŒ„äº†æ¯å€‹ç‰¹å¾µå°æ–¼è¼¸å‡ºæ¨¡å‹é æ¸¬å€¼çš„æ­£å‘ï¼ˆç´…è‰²ï¼‰æˆ–è² å‘ï¼ˆè—è‰²ï¼‰å½±éŸ¿ã€‚å…¨éƒ¨ç´¯åŠ èµ·ä¾†å¾—åˆ°è¼¸å‡ºå€¼ï¼ˆå³æ‰€æœ‰ç‰¹å¾µè²¢ç»ğœ™iå’ŒåŸºæº–å€¼ğœ™0çš„ç¸½å’Œï¼‰ï¼Œå³ç­‰åŒæ–¼å¯¦éš›æ¨¡å‹çš„é æ¸¬ã€‚

```py
index=0
shap.waterfall_plot(shap.Explanation(values=shap_values[0][0][index], 
                                    base_values=explainer.expected_value.numpy()[0], data=X_test[index],  
                                    feature_names=x_feature_names))
```

![](./image/img17-6.png)


## Reference
- Avanti Shrikumar, et al. "[Learning Important Features Through Propagating Activation Differences](https://arxiv.org/abs/1704.02685)." Arxiv, 2017.
- [shap.DeepExplainer](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.DeepExplainer.html#shap-deepexplainer)


- [Interpretability of Deep Learning Models](https://medium.com/towards-data-science/interpretability-of-deep-learning-models-9f52e54d72ab)
- [Additive Feature Attribution Methods](https://medium.com/@jimmywu0621/%E5%8F%AF%E8%A7%A3%E9%87%8B%EF%BD%81%EF%BD%89-%E4%BB%80%E9%BA%BC%E6%98%AFshap-5ec3953e3c5b)
- [Deep SHAP é‘½çŸ³ç¯„ä¾‹](https://towardsdatascience.com/interpretability-of-deep-learning-models-9f52e54d72ab)
- [ç¿»è­¯Deep SHAP é‘½çŸ³ç¯„ä¾‹](https://kknews.cc/zh-tw/code/n9lyk23.html)